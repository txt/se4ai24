<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>stats</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        background-color: #ffffff;
        color: #a0a0a0;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
    div.sourceCode
      { color: #1f1c1b; background-color: #ffffff; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #1f1c1b; } /* Normal */
    code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
    code span.an { color: #ca60ca; } /* Annotation */
    code span.at { color: #0057ae; } /* Attribute */
    code span.bn { color: #b08000; } /* BaseN */
    code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
    code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #924c9d; } /* Char */
    code span.cn { color: #aa5500; } /* Constant */
    code span.co { color: #898887; } /* Comment */
    code span.cv { color: #0095ff; } /* CommentVar */
    code span.do { color: #607880; } /* Documentation */
    code span.dt { color: #0057ae; } /* DataType */
    code span.dv { color: #b08000; } /* DecVal */
    code span.er { color: #bf0303; text-decoration: underline; } /* Error */
    code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
    code span.fl { color: #b08000; } /* Float */
    code span.fu { color: #644a9b; } /* Function */
    code span.im { color: #ff5500; } /* Import */
    code span.in { color: #b08000; } /* Information */
    code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
    code span.op { color: #1f1c1b; } /* Operator */
    code span.ot { color: #006e28; } /* Other */
    code span.pp { color: #006e28; } /* Preprocessor */
    code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #ff5500; } /* SpecialString */
    code span.st { color: #bf0303; } /* String */
    code span.va { color: #0057ae; } /* Variable */
    code span.vs { color: #bf0303; } /* VerbatimString */
    code span.wa { color: #bf0303; } /* Warning */
  </style>
  <link rel="stylesheet" href="style.css" />
  
  <link rel="icon" type="image/x-icon" href="favicon.ico">

  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<div class=wrapper>
<p>
csc 591-024, (8290)<br>
csc 791-024, (8291)<br>
fall 2024, special topics in computer science<br>
Tim Menzies, timm@ieee.org, com sci, nc state
<hr>
<a href="index.html">home</a>
:: <a href="timetable.html">timetable</a>
:: <a href="syllabus.html">syllabus</a>
:: <a href="https://docs.google.com/spreadsheets/d/17m4BWszQvmI3fINgs-C-zyAfavOta7K9qFol5yhmw8w/edit?usp=sharing">groups</a>
:: <a href="https://moodle-courses2425.wolfware.ncsu.edu/course/view.php?id=4181&bp=s">moodle</a>
:: <a href="https://github.com/txt/se4ai24/blob/main/LICENSE">license</a>  </p>
<img src="img/brain.png" align=left width=280
style="padding: 10px; padding-right: 15px; -webkit-filter: drop-shadow(-10px 10px 10px #222); filter: drop-shadow(-10px 10px 10px #222); ">


<header id="title-block-header">
<h1 class="title">stats</h1>
</header>
<p><br clear=all></p>
<h2 id="tldr">Tl;DR</h2>
<p>Find <a
href="https://github.com/timm/ezr/blob/24Aug14/stats.py">stats.py</a></p>
<p>Run <code>python3.13 stats.py</code>.</p>
<p>Collect your Nobel prize.</p>
<h2 id="does-4244">Does 42==44?</h2>
<p>If we watched 100 women and men walk past us and their mean walking
tipped was 42 and 44 cm/second (for men and women respectively), it is
true that men walk faster than women?</p>
<p>This is an example of the problem of comparing samples. Which can get
tricky.</p>
<figure>
<img
src="https://github.com/txt/aa24/assets/29195/5b1331fc-3bba-470e-a6d1-407bac9b7fb6"
alt="image" />
<figcaption aria-hidden="true">image</figcaption>
</figure>
<p>These problem as two parts:</p>
<ul>
<li>Are the samples distinguishable?
<ul>
<li>If we picked a number from one sample, can we tell of it can be
found on the other?</li>
<li>This is the (badly named) singificance test.</li>
</ul></li>
<li>Is the difference between them non-trivial:
<ul>
<li>This is the effect size test</li>
<li>And we want to ignore small effects.</li>
</ul></li>
</ul>
<p>SE example:</p>
<p><img src="img/bugs.png" width=400 align=right></p>
<ul>
<li>Consider software built by teams who are either (a) located in the
same site or (b) distributed around the globe. i- Distributed
development is infamous for lower quality due to geographical dispersion
which raises issues of communication, and problems building mutual
confidence among distributed teams.</li>
<li>However, in 2009, Bird et al. <a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> checked for those
effects in distributed Microsoft projects.
<ul>
<li>They found that management can successful mitigate for these
detrimental effects (team members need to be organized along product
lines and not on their geographical location).</li>
</ul></li>
<li>But in 2013, Kocaguneli et al. <a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a> reported a statistically
significant effect (a decrease) in the quality of software generated by
Microsoft’s distributed development team (compared to developers who
worked locally together).
<ul>
<li>However, they could that the difference in quality was a “small
effect”; i.e. neglicable</li>
<li>i.e. it was not irresponsible for Microsoft to continue on with
distributed development.</li>
</ul></li>
</ul>
<p>Note that the above needed precise definitions for <em>statistically
significant effect</em> and <em>small effect size</em>. How to find
those?</p>
<h2 id="easy-case-means-far-away-and-the-curves-do-not-overlap">Easy
Case: means far away and the curves do not overlap</h2>
<ul>
<li>So the curves are significantly different</li>
<li>with large effect</li>
</ul>
<p><img src="https://github.com/txt/aa24/assets/29195/3a0eaad2-4986-463b-a1f0-e26d8500efae" width=600></p>
<p>Now we increase the standard deviation.</p>
<ul>
<li>So much overalp. Curves may not be significantly different</li>
<li>And now that mean seperation seems less different</li>
</ul>
<p><img src="https://github.com/txt/aa24/assets/29195/ee3e7184-4f78-4c88-bd66-34c2d61c98e5" width=600></p>
<h2 id="terminology">Terminology</h2>
<p>We <em>sample</em> under different <em>treatments</em> (e.g. we put
weights on our people, then ask them to walk around)</p>
<ul>
<li>and the <em>sample size</em> is the number of measurements made per
<em>treatment</em>.</li>
</ul>
<p>Sometimes we assume <em>samples</em> come from different
<em>distributions</em> (e.g. normal, binomial, etc).</p>
<p>We want to know how to separate <em>samples</em> that are
<em>significty distinguisable</em>, by more than a <em>small effect
size</em>.</p>
<h2 id="parametric-statistical-tests">Parametric Statistical Tests</h2>
<p>If we assume that our data comes from a certain distrubtion then we
could write a formula to compute the overlap or, if we throw darts at
both diistributions, waht are the odds that we will hit numbers from one
distribution, not aother.</p>
<p>This is called parametric statisitics. You assume a formula
(e.g. Gaussian) then look to filling in the parameters of that
distribution (for Gaussian, the mean <span
class="math inline">\(\mu\)</span> and the standard deviation <span
class="math inline">\(\sigma\)</span> ).</p>
<p>But there are so many distributions so it is not clear what formula
we should use.</p>
<p><img src="https://github.com/txt/aa24/assets/29195/0d871993-9ddd-4535-aad3-b1d567310e08" width=600></p>
<p>Also, real world data may be conform to a simple single distribution.
For exam,e here are the query times for 50 SQL statements in one
program.</p>
<p><img src="https://github.com/txt/aa24/assets/29195/3ad878b4-4f47-4db2-9a2c-c3e74ac97c29" width=400></p>
<p>If you want a justification for parametric tests:</p>
<ul>
<li>To select a “best” methods, apply the advice of Rosenthal et
al. [46]
<ul>
<li>Rosenthal, R., Cooper, H., Hedges, L.: Parametric measures of effect
size. The handbook of research synthesis 621(2), 231–244 (1994). 3350
citations.</li>
<li>Consider results that are bounded 0..1. Such results are not prone
to extreme outlier effects (such extreme outliers are indicators for
long-tail effects which, in turn suggest that it might be better to use
non-parametric methods).</li>
<li>Assuming no extreme outliers, non-parametric tests have less
statistical power than parametric ones.</li>
<li>Rosenthal et al. discuss different parametric methods for asserting
that one result is with some small effect of another (i.e. it is “close
to”).</li>
<li>They list dozens of effect size tests that divide into two groups:
<ul>
<li>the “r” group that is based on the Pearson correlation
coefficient;</li>
<li>or the d family that is based on absolute differences normalized by
(e.g.) the size of the standard deviation.</li>
</ul></li>
<li>Rosenthal et al. comment that “none is intrinsically better than the
other”.</li>
<li>Here, use the most direct parametric methods.
<ul>
<li>Using a “d” family method, it can be concluded that one distribution
is the same as another if their mean value differs by less than Cohen’s
delta (d*standard deviation). Note that d is computed separately for
each different evaluation measure (recall, false alarm, AUC). To
visualize that “close to” analysis, in all our results:– Any cell that
is within d of the best value will be highlighted in gray. All gray
cells are observed as “winners” and all the other cells are “losers”.–
For recall and AUC, the “best” cells have “highest value” since the
optimization goal is to maximize these values.– For false alarm, the
“best” cells have “lowest value” since false alarms is to be
minimized.</li>
<li>As to what value of d to use in this analysis, we take the advice of
a widely cited paper by Sawilowsky [47] (this 2009 paper has 3470
citations).
<ul>
<li>Sawilowsky, S.S.: New effect size rules of thumb. Journal of Modern
Applied Statistical Methods 8(2), 26 (2009)</li>
<li>That paper asserts that “small” and “medium” effects can be measured
using d = 0.2 and d = 0.5 (respectively).</li>
<li>Splitting the difference, we will analyze this data looking for
differences larger than d = (0.5 + 0.2)/2 = 0.35.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>Warning: I don’t buy the above except for making approx arguments
about the value of X vs Y. So I might use “d= 0.35” to dispense with
tiny differences in results.</p>
<h2 id="non-parametric-stats">Non-parametric stats</h2>
<h3 id="scott-knott">Scott-Knott:</h3>
<p>Many statistical methods (e.g. t-test, Tukey, Duncan, Newman-Keuls
procedures) suffer from have overlapping problems. - By overlapping we
mean the possibility of one or more sample to be classified in more than
one group. - In fact, as the number of samples increase, so to does the
the number of overlaps, which makes it hard to distinguish the real
groups to which the means should belong. - The Scott-Knott method <a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> does not have this problem, what is
often cited as a very good quality of this procedure.</p>
<p>Scott-Kott is a recursive clustering procedure that - sorts the
samples - divided them on the largest expected difference in the mean
before and after division - then recuses on each half, but only if the
two halfs are statistically different</p>
<p>The halves are picked to maximize:</p>
<p><span class="math display">\[    E(\Delta) =
\frac{|l_1|}{|l|}abs(E({l_1}) - E({l}))^2 +
\frac{|l_2|}{|l|}abs(E({l_2}) - E({l}))^2\]</span></p>
<p>(here <span class="math inline">\(|l_1|\)</span> means the size of
list <span class="math inline">\(l_1\)</span>)</p>
<p>For example, support I had four samples labelled <em>x1,x2…</em>
etc</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> some1(n<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  report([ SOME([<span class="fl">0.34</span>, <span class="fl">0.49</span> ,<span class="fl">0.51</span>, <span class="fl">0.6</span>]<span class="op">*</span>n,   txt<span class="op">=</span><span class="st">&quot;x1&quot;</span>),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        SOME([<span class="fl">0.6</span>  ,<span class="fl">0.7</span> , <span class="fl">0.8</span> , <span class="fl">0.89</span>]<span class="op">*</span>n,  txt<span class="op">=</span><span class="st">&quot;x2&quot;</span>),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        SOME([<span class="fl">0.09</span> ,<span class="fl">0.22</span>, <span class="fl">0.28</span> , <span class="fl">0.5</span>]<span class="op">*</span>n, txt<span class="op">=</span><span class="st">&quot;x3&quot;</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        SOME([<span class="fl">0.6</span>  ,<span class="fl">0.7</span>,  <span class="fl">0.8</span> , <span class="fl">0.9</span>]<span class="op">*</span>n,   txt<span class="op">=</span><span class="st">&quot;x4&quot;</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        SOME([<span class="fl">0.1</span>  ,<span class="fl">0.2</span>,  <span class="fl">0.3</span> , <span class="fl">0.4</span>]<span class="op">*</span>n,   txt<span class="op">=</span><span class="st">&quot;x5&quot;</span>)])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>some1()</span></code></pre></div>
<p>I would sort them by their median value the draw a little box plot of
their 10-to-30th values, their median, and their 70-to-90th value:</p>
<pre><code>#
 0, x3,  0.28,  0.06, ------   *----------|                   
 0, x5,  0.30,  0.10, -----     *----     |                   
#
 1, x1,  0.51,  0.02,             ------- *----               
#
 2, x2,  0.80,  0.10,                     |    -----     *--- 
 2, x4,  0.80,  0.10,                     |    -----     *--- </code></pre>
<p>Note the left-handside <code>sk rank</code> column. This reports what
happens after SK sorts the samples and decides which ones are
different</p>
<ul>
<li>A treatment has the same ranked the one before it,
<ul>
<li>it is not statistically distinguishable</li>
<li>by more than small effect.</li>
</ul></li>
</ul>
<p>But how does it do it? The Scott &amp; Knott method make use of a
top-down clustering algorithm, where, starting from the the whole group
of observed mean effects, it divides, and keep dividing the sub-groups
in such a way that the intersection of any two groups formed in that
manner is empty.</p>
<p>This means that <span class="math inline">\(N\)</span> samples might
get ranked using only <span class="math inline">\(\log_2(N)\)</span>
statistical comparisons - and even less, if ever sub-trees high up int
the process are found to be not statistically different - Also,
Scott-Knott converts the problem of ranking samples to clustering
probkem (which I do understand) rather than a stats problem (which, in
all fairness, I understand only weakly).</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sk(somes,epsilon<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">&quot;Sort nums on mid. give adjacent nums the same rank if they are statistically the same&quot;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> sk1(somes, rank, cut<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    most, b4 <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, SOME(somes)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(somes)):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>      lhs <span class="op">=</span> SOME(somes[:j])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>      rhs <span class="op">=</span> SOME(somes[j:])</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>      tmp <span class="op">=</span> (lhs.n<span class="op">*</span><span class="bu">abs</span>(lhs.mid() <span class="op">-</span> b4.mid()) <span class="op">+</span> rhs.n<span class="op">*</span><span class="bu">abs</span>(rhs.mid() <span class="op">-</span> b4.mid())) <span class="op">/</span> b4.n</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> tmp <span class="op">&gt;</span> most <span class="kw">and</span> (somes[j].mid() <span class="op">-</span> somes[j<span class="op">-</span><span class="dv">1</span>].mid()) <span class="op">&gt;</span> epsilon:</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>         most,cut <span class="op">=</span> tmp,j</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cut:</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>      some1,some2 <span class="op">=</span> SOME(somes[:cut]), SOME(somes[cut:])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> <span class="va">True</span>: <span class="co">#not some1.cohen(some2): # and abs(some1.div() - some2.div()) &gt; 0.0001:</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> some1 <span class="op">!=</span> some2:</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>          rank <span class="op">=</span> sk1(somes[:cut], rank) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>          rank <span class="op">=</span> sk1(somes[cut:], rank)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span> rank</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> some <span class="kw">in</span> somes: some.rank <span class="op">=</span> rank</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rank</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  somes <span class="op">=</span> <span class="bu">sorted</span>(somes, key<span class="op">=</span><span class="kw">lambda</span> some: some.mid()) <span class="co">#lambda some : some.mid())</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  sk1(somes,<span class="dv">0</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> somes</span></code></pre></div>
<p>Note the commented out call to <code>some1.cohen(some2)</code>.</p>
<pre class="python3"><code>def cohen(i,j):
      return abs( i.mid() - j.mid() ) &lt; the.stats.cohen * i.pooledSd(j)

def pooledSd(i,j):
   &quot;Return a measure of the combined standard deviation.&quot;
   sd1, sd2 = i.div(), j.div()
   return (((i.n - 1)*sd1 * sd1 + (j.n-1)*sd2 * sd2) / (i.n + j.n-2))**.5</code></pre>
<h2 id="not-equal">Not Equal</h2>
<p>But how to code up <code>!=</code>?. Recall that this needs two
functions</p>
<ul>
<li>Are the sample distinguishable?
<ul>
<li>If we picked a number from one sample, can we tell of it can be
found on the other?</li>
</ul></li>
<li>Is the difference more than a small effect?
<ul>
<li>This is the effect size test</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__eq__</span>(i:SOME, j:SOME) <span class="op">-&gt;</span> <span class="bu">bool</span>:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>      <span class="co">&quot;True if all of cohen/cliffs/bootstrap say you are the same.&quot;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span>  i.cliffs(j) <span class="kw">and</span> i.bootstrap(j) <span class="co">## ordered slowest to fastest</span></span></code></pre></div>
<p>Note that that this is a conjuction; i.e. to prove “different” I have
to prove both things.</p>
<h3 id="cliffsdelta-non-parametric-effect-size">CliffsDelta
(non-parametric effect size)</h3>
<p>This code is simple. For everything <span
class="math inline">\(x\)</span> in one sample, look in the other sample
- Count how often there are bigger and larger numbers in the other
sample. - If <span class="math inline">\(x\)</span> has many numbers
less and greater than me, then I tend to be the same as the other sample
- Since I tend to fall to the middle of the other sample</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> cliffs(i:SOME, j:SOME , dull<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>      <span class="co">&quot;&quot;&quot;non-parametric effect size. threshold is border between small=.11 and medium=.28</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">      from Table1 of  https://doi.org/10.3102/10769986025002101&quot;&quot;&quot;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>      n,lt,gt <span class="op">=</span> <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> x1 <span class="kw">in</span> i.has():</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> y1 <span class="kw">in</span> j.has():</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>          n <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> x1 <span class="op">&gt;</span> y1: gt <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> x1 <span class="op">&lt;</span> y1: lt <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">abs</span>(lt <span class="op">-</span> gt)<span class="op">/</span>n  <span class="op">&lt;</span> (dull <span class="kw">or</span> the.stats.cliffs <span class="kw">or</span> <span class="fl">0.197</span>)</span></code></pre></div>
<h3 id="bootstrap-non-parametric-test-for-distinguish-ablity">Bootstrap
(non-parametric test for “distinguish-ablity”)</h3>
<ul>
<li>Summarize the difference in two samples with some <code>obs</code>
(observartion)</li>
<li>Hundreds of times
<ul>
<li>Sample with replacement from both samples</li>
<li>Count how often the observation is larger than the baseline
<code>obs</code>.</li>
</ul></li>
<li>The higher that count, the harder it is to seperate you
<ul>
<li>so the lower that count, the more we are sure you are
different.</li>
</ul></li>
</ul>
<p>Here’s the code for that. <code>yhat</code> and <code>zhat</code> are
transforms recommended by Efron and Tibshirani to level the playing
field (ensures that both distribution s are scored on mean value that is
common to both distributions).</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span>  bootstrap(i:SOME, j:SOME,confidence<span class="op">=</span><span class="va">None</span>,bootstraps<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>      <span class="co">&quot;&quot;&quot;non-parametric significance test From Introduction to Bootstrap, </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Efron and Tibshirani, 1993, chapter 20. https://doi.org/10.1201/9780429246593&quot;&quot;&quot;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>      y0,z0  <span class="op">=</span> i.has(), j.has()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>      x,y,z  <span class="op">=</span> SOME(inits<span class="op">=</span>y0<span class="op">+</span>z0), SOME(inits<span class="op">=</span>y0), SOME(inits<span class="op">=</span>z0)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>      delta0 <span class="op">=</span> y.delta(z)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>      yhat   <span class="op">=</span> [y1 <span class="op">-</span> y.mid() <span class="op">+</span> x.mid() <span class="cf">for</span> y1 <span class="kw">in</span> y0]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>      zhat   <span class="op">=</span> [z1 <span class="op">-</span> z.mid() <span class="op">+</span> x.mid() <span class="cf">for</span> z1 <span class="kw">in</span> z0] </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>      pull   <span class="op">=</span> <span class="kw">lambda</span> l:SOME(random.choices(l, k<span class="op">=</span><span class="bu">len</span>(l))) </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>      samples<span class="op">=</span> bootstraps <span class="kw">or</span> the.stats.bootstraps <span class="kw">or</span> <span class="dv">512</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>      n      <span class="op">=</span> <span class="bu">sum</span>(pull(yhat).delta(pull(zhat)) <span class="op">&gt;</span> delta0  <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(samples)) </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> n <span class="op">/</span> samples <span class="op">&gt;=</span> (confidence <span class="kw">or</span> the.stats.confidence <span class="kw">or</span> <span class="fl">0.05</span>)</span></code></pre></div>
<h2 id="things-to-note">Things to Note</h2>
<h3 id="blurring">Blurring</h3>
<p>“The point was that you have to look at the world as it is, not as
some elegant theory says it ought to be.” — M. Mitchell Waldrop</p>
<p><img src="img/blurring.png" align=right width=500></p>
<p>When dealing with many treatments with larte variance,</p>
<ul>
<li>results may “<em>blur</em>”</li>
<li>i.e. many of them are statistically indistinguishable.</li>
</ul>
<p>For example, at left, 51 of the 55 treatments all receive the same
rank.</p>
<p>When such blurring occurs,</p>
<ul>
<li>we can conclude is that some of the distinctions made during
sampling were unimportant (in the sense that it does not distinguish the
individual treatments).</li>
<li>Which can lead to some startling results….</li>
</ul>
<p>For another example, consider <a
href="https://github.com/timm/lean/blob/master/src/knn.lua">knn
results</a> that scores nearest-neighbor regression using <span
class="math inline">\(100*(predicted-actual)/predicted\)</span></p>
<ul>
<li>Using <span class="math inline">\(k \in \{1,2,4,8}\)</span> nearest
neighbors</li>
<li>Via training set that contains <span class="math inline">\(N \in
\{512,256,128,32\}\)</span> rows selected at random from auto.csv</li>
<li>Using a distance function <span class="math inline">\(p \in
\{1,2,4,8\}\)</span> for <span class="math inline">\((\sum_i
(x_i-y_i)^p)^{1/p}\)</span> (and recall that <span
class="math inline">\(p=2\)</span> is Euclidean)</li>
<li>Where the conclusions of those near neighbors are combined via a
median or triangular kernel function
<ul>
<li>median means “pick the middle value”</li>
<li>triangular means “closer values are weighted more”</li>
</ul></li>
</ul>
<p><span class="math display">\[ \mathit{prediction}= \frac{\sum_i
n_i/d_i}{\sum_i 1/d_i} \]</span></p>
<p>Please consider <span class="math inline">\((k=4,p=4, N=32,
f=\mathit{triangle})\)</span>. Notice anything interesting? ### Runtimes
and Storage</p>
<p>Parametric stats are very fast and consume little memory (jsut the
memory required for the params).</p>
<p>Non-parametric stats are slower (see all that sampling inside
<code>_bootstrap</code> and that <span
class="math inline">\(O(N^2)\)</span> traversal inside
<code>cliffsDelta</code>). So don’t run non-parametric tests inside the
inner-most loop of your reasonong.</p>
<p>If you need a quick and dirty check for differences, just check if
the mean difference is larger than a third of the standard deviation of
the sample. No, this test is not well-founded. But it is useful as a
heuristic.</p>
<p>Then, once you have collected results from (say) 20 repeated runs,
run these non-parametric tests as part of your final report
generation.</p>
<h3 id="statistical-wars">Statistical Wars</h3>
<p>So much discussion of “what stats is best”. Very little
experimentation on data.</p>
<p>here,s we asking cfliffsDelta (cd), boostrapping (boot), conjuction
of both, and sd/3 if two sample are different wjere</p>
<ul>
<li>sample1 is 20 numbers from a gaussian (mean=10, sd=3)</li>
<li>sample2 is just <span class="math inline">\(x_i *
\mathit{inc}\)</span></li>
</ul>
<p>Note the large areas of agreement, with a small dispute zone in the
middle.</p>
<table>
<thead>
<tr>
<th>inc</th>
<th>cd</th>
<th>boot</th>
<th>c+b</th>
<th>sd/3</th>
<th style="text-align: center;">dispute?</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.02</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.04</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.061</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.082</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.104</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.126</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.149</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.172</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.195</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.219</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.243</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td style="text-align: center;">n</td>
</tr>
<tr>
<td>1.268</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.294</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.319</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.346</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.373</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.4</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.428</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.457</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td>1.486</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>C. Bird, N. Nagappan, P. T. Devanbu, H. Gall, and B.
Murphy. Does distributed development affect software quality? an
empirical case study of windows vista. In ICSE, pages 518–528, 2009.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Kocaguneli, E., Zimmermann, T., Bird, C., Nagappan, N.,
&amp; Menzies, T. (2013, May). Distributed development considered
harmful?. In 2013 35th International Conference on Software Engineering
(ICSE) (pp. 882-890). IEEE.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Scott R.J., Knott M. 1974. A cluster analysis method for
grouping mans in the analysis of variance. Biometrics, 30, 507-512.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>




</div>
</body>
</html>
