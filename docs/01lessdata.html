<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>How Much Data?</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  
  <link rel="icon" type="image/x-icon" href="favicon.ico">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<div class=wrapper>
<p>
csc 591-024, (8290)<br>
csc 791-024, (8291)<br>
fall 2024, special topics in computer science<br>
Tim Menzies, timm@ieee.org, com sci, nc state
<hr>
<a href="index.html">home</a>
:: <a href="timetable.html">timetable</a>
:: <a href="syllabus.html">syllabus</a>
:: <a href="groups.html">groups</a> 
:: <a href="https://moodle-courses2425.wolfware.ncsu.edu/course/view.php?id=4181&bp=s">moodle</a>
:: <a href="https://github.com/txt/se4ai24/blob/main/LICENSE">license</a>  </p>
<img src="img/brain.png" align=left width=280
style="padding: 10px; padding-right: 15px; -webkit-filter: drop-shadow(-10px 10px 10px #222); filter: drop-shadow(-10px 10px 10px #222); ">


<header id="title-block-header">
<h1 class="title">How Much Data?</h1>
</header>
<p><br clear=both></p>
<h2 id="how-much-data-do-we-need-for-learning">How Much data Do we need
for Learning?</h2>
<ul>
<li>“The Unreasonable Effectiveness of Data,” by Google’s then Chief
Scientist Peter Norvig
<ul>
<li>“Billions of trivial data points can lead to understanding” <a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> (a claim he supports with numerous
examples from vision research).</li>
</ul></li>
<li>In software analytics, data-hungry researchers assume that if data
is useful, then even more data is much more useful. For example:
<ul>
<li>“..as long as it is large; the resulting prediction performance is
likely to be boosted more by the size of the sample than it is hindered
by any bias polarity that may exist” <a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>.</li>
<li>“It is natural to think that a closer previous release has more
similar characteristics and thus can help to train a more accurate
defect prediction model. It is also natural to think that accumulating
multiple releases can be beneficial because it represents the
variability of a project” <a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>.</li>
<li>“Long-term JIT models should be trained using a cache of plenty of
changes” <a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>.</li>
</ul></li>
</ul>
<h2 id="before-we-start.">Before We Start….</h2>
<p>Review questions?</p>
<ol type="1">
<li>What is the standard line on “how much data is enough?”
<ul>
<li>From Peter Norvig</li>
<li>From regression theory</li>
<li>From semi-supervised learning</li>
</ul></li>
<li>Describe each of the following. What are their implications for
human decision making
<ul>
<li>Streaming over zero-diversity data</li>
<li>STM, LTM</li>
<li>Shrikanth’s early bird effect</li>
<li>two results (Valerdi’s work; repertory grids) commenting on the rate
at which we can extract considered opinions from humans</li>
</ul></li>
<li>In English, describe the following math results and their
implications for data mining
<ul>
<li>chesboard model</li>
<li>probable correctness theory.</li>
</ul></li>
<li>Few-shot learning:
<ol type="1">
<li>describe it</li>
<li>In what sense does FSL mean we can look at fewer examples?</li>
<li>In what sense does FSL require many, many examples?</li>
</ol></li>
</ol>
<h2 id="a-more-informed-position-the-question-is-wrong">A more informed
position: The question is wrong</h2>
<ul>
<li>It depends on the nature of the data
<ul>
<li>e.g. if I show you, one at a time, 100 “1”s then we are pretty sure
the 101-th thing will be “1”.</li>
<li>So if data clusters to regions with not much variance
<ul>
<li>then once we find those regions, we can stop</li>
</ul></li>
</ul></li>
<li>And sometimes its not what the data is…
<ul>
<li>.. but when we collect it</li>
<li>Shrikanth and Menzies: the early bird hypothesis
<ul>
<li>data learned from the first 150 commits builds a model as good as
anything else <a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>;</li>
<li>data from the early in the lifecycle is richer in examples of things
going wrong</li>
</ul></li>
</ul></li>
</ul>
<p><img width="898" alt="image" src="https://github.com/txt/aa24/assets/29195/51809d84-6c32-4d86-849d-0af40273c83f"></p>
<h2 id="another-question-how-much-data-can-you-handle">Another question:
How much data can you handle?</h2>
<p>For very fast decision making, there is a cognitive science case that
we work from less than a dozen examples:</p>
<ul>
<li>Larkin et al. <a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> characterize human expertise in
terms of very small short term memory, or STM (used as a temporary
scratch pad for current observation) and a very large long term memory,
or LTM.</li>
<li>The LTM holds separate tiny rule fragments that explore the contents
of STM to say “when you see THIS, do THAT”.</li>
<li>When an LTM rule triggers, its consequence can rewrite STM contents
which, in turn, can trigger other rules</li>
<li>Short term memory is very small, perhaps even as small as four to
seven items <a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> <a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a>.</li>
<li>Experts are experts, says Larkin et al. <a href="#fn9"
class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>
because the patterns in their LTM patterns dictate what to do, without
needing to pause for reflection.</li>
<li>Novices perform worse than experts, says Larkin et al., when they
fill up their STM with too many to-do’s where they plan to pause and
reflect on what to do next.</li>
<li>Since, experts post far fewer to-do’s in their STMs, they complete
their tasks faster because (a) they are less encumbered by excessive
reflection and (b) there is more space in their STM to reason about new
information.</li>
</ul>
<p>While first proposed in 1981, this STM/LTM theory still remains
relevant <a href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a>. This theory can be used to explain
both expert competency and incompetency in software engineering tasks
such as understanding code <a href="#fn11" class="footnote-ref"
id="fnref11" role="doc-noteref"><sup>11</sup></a>.</p>
<h2 id="another-question-how-much-data-can-you-get">Another question:
How much data can you get?</h2>
<p>How fast can we gather expert opinion?</p>
<ul>
<li>Some can monitor products on an assembly line, 1000s of items per
day
<ul>
<li>And there will be some error rate</li>
</ul></li>
<li>But suppose we have a panel of experts?
<ul>
<li>And suppose they have to check with everyone else before making a
decision?</li>
<li>Then everything they conclude has to be analysed, certified</li>
</ul></li>
</ul>
<p>Evidence from “cost estimation”</p>
<ul>
<li>Valerdi <a href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a> reports that panels of human
experts required three meetings (three hours each) to reach convergence
on the influence of 10 variables on 10 examples (in the domain of cost
estimation).</li>
</ul>
<p>Evidence from “Repertory Grids”</p>
<ul>
<li>A structure interview technique, learn the dimensions incrementally
as we go:
<ol type="1">
<li>Take three examples <span
class="math inline">\(E_1,E_2,E_3\)</span>:</li>
</ol>
<ul>
<li>Which one is most distant?</li>
<li>Along what dimension <span class="math inline">\(D_i\)</span> is it
distant?</li>
<li>Score those examples on this dimensions.</li>
</ul>
<ol start="2" type="1">
<li>Goto to step 1.</li>
</ol></li>
</ul>
<p><img align=600 
     src="https://csdl-images.ieeecomputer.org/mags/so/2007/02/figures/s20534.gif"></p>
<p>Advice on how long to fill in a rep grid?</p>
<ul>
<li>Kington <a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a>:
<ul>
<li>One hour to walk thorugh <span class="math inline">\(E=16\)</span>
examples with <span class="math inline">\(D=16\)</span> dimensions.</li>
</ul></li>
<li>Easterby-Smith <a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a>:
<ul>
<li>Keep the grid small.</li>
<li>A grid containing ten elements and ten constructs may take two hours
to complete.</li>
<li>Larger grids may take substantially more time</li>
</ul></li>
<li>Edwards’s <a href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a> rep grid interview sessions lasted,
on average, for one hour (although the shortest was 30 min) and these
were recorded for later analysis.</li>
</ul>
<p>Overall, we get, for reflective labels on data:</p>
<ul>
<li>10 to 20 examples per 1-4 hours</li>
</ul>
<h2 id="advice-from-mathematics">Advice from Mathematics</h2>
<p>One commonly cited rule of thumb [^call] is to have at least 10 times
the number of training data instances attributes <a href="#fn16"
class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>
<a href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a>.</p>
<ul>
<li>by this rule, 20 attributes needs 200 rows</li>
</ul>
<h2 id="historically-how-much-data-was-enough">Historically, how much
data was enough?</h2>
<ul>
<li>Semi-supervised learning: <span
class="math inline">\(\sqrt{N}\)</span> is enough
<ul>
<li>Alvarez <a href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a> recursively bi-cluster down to
<span class="math inline">\(\sqrt{N}\)</span> then collect one data
point per leaf cluster.</li>
</ul></li>
</ul>
<ul>
<li>Zhu et al. <a href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a>
<ul>
<li>Numerous examples from facial recognition where face accuracy
plateaus at <span class="math inline">\(M&gt; 100\)</span> examples</li>
</ul></li>
<li>Incremental learning in SE: <a href="#fn20" class="footnote-ref"
id="fnref20" role="doc-noteref"><sup>20</sup></a>
<ul>
<li>Sort data on historical order;</li>
<li>Train up to time <span class="math inline">\(t\)</span>, test of
data after <span class="math inline">\(t\)</span>.</li>
<li>Even with 1000s of examples
<ul>
<li>Learning on 25 defective examples + 25 non-defective</li>
<li>Did as good as anything else.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="maths">Maths</h2>
<h3 id="chess-board-model">Chess board model</h3>
<p>Data is spread out across a d-dimensional chessboard where each
dimension is divided into <span class="math inline">\(b\)</span> bins <a
href="#fn21" class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a>.</p>
<ul>
<li>Data is skewed by some factor <span class="math inline">\(k\)</span>
such that not all cells have data.</li>
<li>a standard chess board is <span
class="math inline">\(d,b=2,8\)</span></li>
</ul>
<p>The target is some subset of the data that falls into some of the
chessboard cells:</p>
<ul>
<li><span class="math inline">\(c=b^{-d}\)</span> is the probability of
picking a particular cell;</li>
<li><span class="math inline">\(C=1-(1-p)^n\)</span> is the certainties
that once we arrive at a cells, that we can find the signal after <span
class="math inline">\(n\)</span> attempts (which occurs at probability
<span class="math inline">\(p\)</span> in that cell)</li>
<li>So lets do some simulations. 1,000 times pick at random from the
following:
<ul>
<li><span class="math inline">\(k \in \{ 1, 2, 3, 4, 5\}\)</span></li>
<li><span class="math inline">\(d \in \{ 3, 4, 5, 6, 7\}\)</span>
dimensions;</li>
<li><span class="math inline">\(b \in \{ 2 , 3, 4, 5, 6, 7\}\)</span>
bins;</li>
<li><span class="math inline">\(p \in \{0.1, 0.2, 0,3,
0.4\}\)</span></li>
<li>We gave the whole thing to a decision tree learner, asking what
factors predicts for more than 67% chance of finding the target.
<ul>
<li>and the learnt tree told us:
<ul>
<li>We need up to 200 examples when the defect signal is rare (<span
class="math inline">\(p\le 10\)</span> percent)</li>
<li>But far fewer when the signal occurs at <span
class="math inline">\(p &gt; 10\)</span> percent.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="probable-correctness-theory">Probable Correctness Theory</h3>
<p>Richard Hamlet, Probable correctness theory, 1980 <a href="#fn22"
class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a>.</p>
<ul>
<li>Confidence <span class="math inline">\(C\)</span> that we will see
an event at probability <span class="math inline">\(p\)</span> after
<span class="math inline">\(n\)</span> random trials:
<ul>
<li><span class="math inline">\(C(p,n) =1-(1-p)^n\)</span></li>
</ul></li>
<li>Which re-arranges to:
<ul>
<li><span class="math inline">\(n(C,p) =
\frac{\log(1-C)}{\log(1-p)}\)</span></li>
</ul></li>
<li>And if we have a sorting trick to divide examples into <em>best</em>
and <em>rest</em>
<ul>
<li>then the number of evals is <span
class="math inline">\(\log_2(n(C,p))\)</span></li>
</ul></li>
</ul>
<p>Some what ifs: - If we apply Cohen’s rule (things are
indistinguishable if less than <span
class="math inline">\(d{\times}\sigma\)</span> apart, - And if variables
are Gaussian ranging <span class="math inline">\(-3 \le x \le
3\)</span>. - Then that space divides into regions of size <span
class="math inline">\(p=\frac{d}{6}\)</span></p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 20%" />
<col style="width: 36%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">scenario</th>
<th style="text-align: left;">d</th>
<th style="text-align: left;">p</th>
<th style="text-align: left;">C</th>
<th style="text-align: left;">n(c,p)</th>
<th style="text-align: left;"><span
class="math inline">\(\log_2(n(c,p))\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">medium effect, non-safety critical</td>
<td style="text-align: left;">0.35</td>
<td style="text-align: left;">0.06</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">6</td>
</tr>
<tr class="even">
<td style="text-align: left;">small effect, safety criticali</td>
<td style="text-align: left;">0.2</td>
<td style="text-align: left;">0.03</td>
<td style="text-align: left;">0.9999</td>
<td style="text-align: left;">272</td>
<td style="text-align: left;">8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">tiny effects, ultra-safety critical</td>
<td style="text-align: left;">n/a</td>
<td style="text-align: left;">one in a million</td>
<td style="text-align: left;">six sigma<br> (0.999999)</td>
<td style="text-align: left;">13,815,504</td>
<td style="text-align: left;">24</td>
</tr>
</tbody>
</table>
<p>Note the above table makes some very optimistic assumptions about the
problem:</p>
<ul>
<li>It is single variable Gaussian</li>
<li>Solutions are spaced equally across the x-axis</li>
</ul>
<p>But it also tells us that the only way we can reason about safety
critical systems is via some sorting heuristic (so we can get the log2
effect) [^call]: Application of machine learning techniques in small
sample clinical studies, from StackExchange.com
https://stats.stackexchange.com/questions/1856/application-of-machine-learning-techniques-in-small-sample-clinical-studies</p>
<h2 id="few-shot-learning">Few shot Learning</h2>
<p>In the following, the author says <strong>LLMs</strong> not
<strong>learners</strong> but given the results of this subject, I think
an edit is in order:</p>
<ul>
<li>A particularly exciting aspect of <strong>learners</strong> is their
knack for few-shot and zero-shot learning: they can learn to perform a
task with very few examples. Few- shotting has particular synergies in
software engineering, where there are a lot of phenomena (identifier
names, APIs, terminology, coding patterns) that are known to be highly
project-specific. However, project-specific data can be quite limited,
especially early in the history of a project; thus the few-shot learning
capacity of <strong>learners</strong> might be very relevant.</li>
<li>In the extreme case, training data consists of only one instance for
each target class, which is known as one-shot learning</li>
</ul>
<p>Need another name</p>
<ul>
<li>Few-shot learning is usually a neural model concept
<ul>
<li>Uses a large language models trained on massive code corpora</li>
<li>Generalize to new tasks via a sequence of prompts, starting composed
of natural language instructions, then few instances of task
demonstration, and a query</li>
</ul></li>
<li>Few-shot learning (version 2.0)
<ul>
<li>takes no model as an input (but it could be initialized from a model
learned at a prior session)</li>
<li>Generalize to new tasks via a sequence of queries to the data,
selected by the model built so far.<br />
</li>
</ul></li>
<li>Perhaps it might be useful to combine SMO and few-shot into another
term</li>
</ul>
<p>Generalize to new tasks via a sequence of prompts, starting composed
of natural language instructions,</p>
<ul>
<li>Data-Efficient Sequential Learning (DESL)
<ul>
<li>Sequential Decision-Making : how to making decisions one after
another, where each decision is based on prior outcomes.</li>
<li>Data Selection Strategy : how to selecting which data points to
label or otherwise interact with next. In SMO, this is the acquire
function.</li>
<li>Model Adaptivity : how to update your models for SDM and/or DSS as a
result of the interaction seen in DSS</li>
<li>Label Efficiency : concerns the cost of labelling. DESL is least
useful when the label effeciency is high.</li>
</ul></li>
<li>Other analogous terms include active learning which in statistics
literature also called optimal experimental design or query learning, is
a class of strategies to choose the data from which to learn.</li>
</ul>
<p>Few-shot learning is a subfield of machine learning and deep learning
that aims to teach AI models how to learn from only a small number of
labeled training data.</p>
<p>More generally “n-shot learning” a category of artificial
intelligence that also includes:</p>
<ul>
<li>one-shot learning (in which there is only one labeled example of
each class to be learned)</li>
<li>and zero-shot learning (in which there are no labeled examples at
all</li>
</ul>
<p>Applications:</p>
<ul>
<li>Healthcare: rarity of certain conditions or the expertise required
to accurately annotate medical data (like MRIs or echocardiography) can
make the acquisition of a large number of labeled samples prohibitively
difficult</li>
<li>Robotics: enable robots to quickly adapt to new environments</li>
<li>SE: Any learning task when labels are short: e.g. what tests to run
next, etc etc</li>
</ul>
<p>Methods:</p>
<ul>
<li>Transfer learning (use knowledge from elsewhere)
<ul>
<li>adapt a pre-trained model</li>
<li>e.g. for us in SMO, initialize our best,rest models from prior
applications
<ul>
<li>this can be very useful since, rarely, do we ever do things
once</li>
<li>if it is important, we will do it again and again and again…</li>
</ul></li>
</ul></li>
<li>Data-level approach
<ul>
<li>automatically generate additional training samples</li>
<li>Data generation
<ul>
<li>GANs (generative adaptive networks)
<ul>
<li>Two models discriminator and adversary</li>
<li>Model1 produces</li>
<li>Model2 classifies as right,wrong</li>
<li>Model1 stops when model2 can no long distinguish good from bad</li>
<li>Feedback from one model can be used to guide the other</li>
<li>And if you thought one deep learner was slow, try running two</li>
</ul></li>
</ul></li>
<li>Data augmentation
<ul>
<li>Find ways to add in the missing bits</li>
<li>Semi-supervised learning e.g. RRP, label once per leaf, share the
label across entire leaf</li>
<li>Active learning; e.g. SMO, only ask for labels on most informative
examples.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="few-shot-learning-in-se">Few Shot Learning in SE</h3>
<p>March 2024: Google query: “few-shot learning and ‘software
engineering’”</p>
<p>In the first 100 returns, after paper70, no more published few shot
learning papers in SE.</p>
<p>In the remaining 70 papers:</p>
<table style="width:100%;">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="header">
<th>year</th>
<th>citations</th>
<th>venue</th>
<th>j=journal; <br>c=conf;<nr> w=workshop</th>
<th>title</th>
<th>pdf</th>
<th>data</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2023</td>
<td>1</td>
<td>Icse_NLBSE</td>
<td>w</td>
<td>Few-Shot Learning for Issue Report Classification</td>
<td><a
href="Few-Shot_Learning_for_Issue_Report_Classification.pdf">pdf</a></td>
<td>200 + 200</td>
</tr>
<tr class="even">
<td>2023</td>
<td>2</td>
<td>SSBSE</td>
<td>c</td>
<td>. Search-based Optimisation of LLM Learning Shots for Story Point
Estimation</td>
<td><a href="SB_LLM_Shot_optimisation.pdf">pdf</a></td>
<td>6 to 10</td>
</tr>
<tr class="odd">
<td>2023</td>
<td>2</td>
<td>ICSE</td>
<td>c</td>
<td>Log Parsing with Prompt-based Few-shot Learning</td>
<td><a
href="Log_Parsing_with_Prompt-based_Few-shot_Learning.pdf">pdf</a></td>
<td>4 to 128. most improvement before 16</td>
</tr>
<tr class="even">
<td>2023</td>
<td>3</td>
<td>AST</td>
<td>c</td>
<td>FlakyCat: Predicting Flaky Tests Categories using Few-Shot
Learning</td>
<td><a
href="FlakyCat_Predicting_Flaky_Tests_Categories_using_Few-Shot_Learning.pdf">pdf</a></td>
<td>400+</td>
</tr>
<tr class="odd">
<td>2023</td>
<td>5</td>
<td>ICSE</td>
<td>c</td>
<td>Retrieval-Based Prompt Selection for Code-Related Few-Shot
Learning</td>
<td><a
href="Retrieval-Based_Prompt_Selection_for_Code-Related_Few-Shot_Learning.pdf">pdf</a></td>
<td>6-7 (for code generation (40 to 50 (for code repair)</td>
</tr>
<tr class="even">
<td>2022</td>
<td>7</td>
<td>Soft.Lang.Eng</td>
<td>c</td>
<td>Neural Language Models and Few Shot Learning for Systematic
Requirements Processing in MDSE</td>
<td><a href="3567512.3567534.pdf">pdf</a></td>
<td>8 to 11</td>
</tr>
<tr class="odd">
<td>2023</td>
<td>12</td>
<td>ICSE</td>
<td>c</td>
<td>Towards using Few-Shot Prompt Learning for Automating Model
Completion</td>
<td><a
href="Towards_using_Few-Shot_Prompt_Learning_for_Automating_Model_Completion.pdf">pdf</a></td>
<td>212 classes</td>
</tr>
<tr class="even">
<td>2020</td>
<td>15</td>
<td>IEEE ACCECSS</td>
<td>j</td>
<td>Few-Shot Learning Based Balanced Distribution Adaptation for
Heterogeneous Defect Prediction</td>
<td><a
href="Few-Shot_Learning_Based_Balanced_Distribution_Adaptation_for_Heterogeneous_Defect_Prediction.pdf">pdf</a></td>
<td>100s - 1000s</td>
</tr>
<tr class="odd">
<td>2019</td>
<td>21</td>
<td>Big Data</td>
<td>j</td>
<td>. Exploring the applicability of low-shot learning in mining
software repositories</td>
<td><a href="s40537-019-0198-z.pdf">pdf</a></td>
<td>100 =&gt;70% accuracy; 100s ==&gt; 90% accuracy</td>
</tr>
<tr class="even">
<td>2021</td>
<td>27</td>
<td>ESEM</td>
<td>c</td>
<td>An Empirical Examination of the Impact of Bias on Just-in-time
Defect Prediction</td>
<td></td>
<td>10^3 samples of defects</td>
</tr>
<tr class="odd">
<td>2020</td>
<td>29</td>
<td>ICSE</td>
<td>c</td>
<td>Unsuccessful Story about Few Shot Malware Family Classification and
Siamese Network to the Rescue</td>
<td><a href="3377811.3380354.pdf">pdf</a></td>
<td>10,000s ?</td>
</tr>
<tr class="even">
<td>2022</td>
<td>65</td>
<td>ASE</td>
<td>c</td>
<td>Few-shot training LLMs for project-specific code-summarization</td>
<td><a href="3551349.3559555.pdf">pdf</a></td>
<td>10 samples</td>
</tr>
<tr class="odd">
<td>2022</td>
<td>101</td>
<td>FSE</td>
<td>c</td>
<td>Less Training_ More Repairing Please: Revisiting Automated Program
Repair via Zero-Shot Learning</td>
<td><a href="3540250.3549101.pdf">pdf</a></td>
<td>?</td>
</tr>
</tbody>
</table>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>P. Norvig. (2011) The Unreasonable Effectiveness of
Data. Youtube. https://www.youtube.com/watch?v=yvDCzhbjYWs<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>F. Rahman, D. Posnett, I. Herraiz, and P. Devanbu,
“Sample size vs. bias in defect prediction,” in Proceedings of the 2013
9th joint meeting on foundations of software engineering. ACM, 2013,
pp. 147–157.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>S. Amasaki, “Cross-version defect prediction: use
historical data, crossproject data, or both?” Empirical Software
Engineering, pp. 1–23, 2020.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>S. McIntosh and Y. Kamei, “Are fix-inducing changes a
moving target? a longitudinal case study of just-in-time defect
prediction,” IEEE Transactions on Software Engineering, vol. 44, no. 5,
pp. 412–428, 2017.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>S. N.C., S. Majumder and T. Menzies, “Early Life Cycle
Software Defect Prediction. Why? How?,” 2021 IEEE/ACM 43rd International
Conference on Software Engineering (ICSE), Madrid, ES, 2021,
pp. 448-459, doi: 10.1109/ICSE43902.2021.00050.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Jill Larkin, John McDermott, Dorothea P. Simon, and
Herbert A. Simon. 1980. Expert and Novice Performance in Solving Physics
Problems. Science 208, 4450 (1980), 1335–1342.
DOI:http://dx.doi.org/10.1126/science.208.4450.1335
arXiv:http://science.sciencemag.org/content/208/4450/1335.full.pdf<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>N. Cowan. 2001. The magical number 4 in short-term
memory: a reconsideration of mental storage capacity. Behav Brain Sci
24, 1 (Feb 2001), 87–114.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>George A Miller. 1956. The magical number seven, plus or
minus two: some limits on our capacity for processing information.
Psychological review 63, 2 (1956), 81.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Jill Larkin, John McDermott, Dorothea P. Simon, and
Herbert A. Simon. 1980. Expert and Novice Performance in Solving Physics
Problems. Science 208, 4450 (1980), 1335–1342.
DOI:http://dx.doi.org/10.1126/science.208.4450.1335
arXiv:http://science.sciencemag.org/content/208/4450/1335.full.pdf<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Recently, Ma et al. [^wei14] used evidence from
neuroscience and functional MRIs to argue that STM capacity might be
better measured using other factors than “number of items”. But even
they conceded that “the concept of a limited (STM) has considerable
explanatory power for behavioral data”.<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Susan Wiedenbeck, Vikki Fix, and Jean Scholtz. 1993.
Characteristics of the mental representations of novice and expert
programmers: an empirical study. International Journal of Man-Machine
Studies 39, 5 (1993), 793–812.<a href="#fnref11" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Valerdi, Ricardo. “Heuristics for systems engineering
cost estimation.” IEEE Systems Journal 5.1 (2010): 91-98.<a
href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Kington, Alison. “Defining Teachers’ Classroom
Relationships.” (2009).
https://eprints.worc.ac.uk/1885/1/Kington%202009.pdf<a href="#fnref13"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Easterby-Smith, Mark. “The Design, Analysis and
Interpretation of Repertory Grids.” Int. J. Man Mach. Stud. 13 (1980):
3-24.<a href="#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Helen M. Edwards, Sharon McDonald, S. Michelle Young,
The repertory grid technique: Its place in empirical software
engineering research, Information and Software Technology, Volume 51,
Issue 4, 2009, Pages 785-798, ISSN 0950-5849,<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Austin PC, Steyerberg EW. Events per variable (EPV) and
the relative performance of different strategies for estimating the
out-of-sample validity of logistic regression models. Stat Methods Med
Res. 2017 Apr;26(2):796-808. doi: 10.1177/0962280214558972. Epub 2014
Nov 19. PMID: 25411322; PMCID: PMC5394463.<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>Peduzzi P, Concato J, Kemper E, Holford TR, Feinstein
AR. A simulation study of the number of events per variable in logistic
regression analysis. J Clin Epidemiol. 1996 Dec;49(12):1373-9. doi:
10.1016/s0895-4356(96)00236-3. PMID: 8970487.<a href="#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Alvarez, L., &amp; Menzies, T. (2023). Don’t Lie to Me:
Avoiding Malicious Explanations With STEALTH. IEEE Software, 40(3),
43-53.<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>Zhu, X., Vondrick, C., Fowlkes, C.C. et al. Do We Need
More Training Data?. Int J Comput Vis 119, 76–92 (2016).
https://doi-org.prox.lib.ncsu.edu/10.1007/s11263-015-0812-2<a
href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>Menzies, T., Turhan, B., Bener, A., Gay, G., Cukic, B.,
&amp; predictors. In Proceedings of the 4th international workshop on
Predictor models in software engineering (pp. 47-54).<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>J. Nam, W. Fu, S. Kim, T. Menzies and L. Tan,
“Heterogeneous Defect Prediction,” in IEEE Transactions on Software
Engineering, vol. 44, no. 9, pp. 874-896, 1 Sept. 2018, doi:
10.1109/TSE.2017.2720603.<a href="#fnref21" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>Hamlet, Richard G. “Probable correctness theory.”
Information processing letters 25.1 (1987): 17-25.<a href="#fnref22"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>




</div>
</body>
</html>
